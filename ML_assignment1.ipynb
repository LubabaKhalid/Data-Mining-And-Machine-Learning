{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6c0a65c-96c1-4a5b-93a4-8cc02f4fdc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic Dataset:\n",
      "   pclass  survived                                             name     sex  \\\n",
      "0     1.0       1.0                    Allen, Miss. Elisabeth Walton  female   \n",
      "1     1.0       1.0                   Allison, Master. Hudson Trevor    male   \n",
      "2     1.0       0.0                     Allison, Miss. Helen Loraine  female   \n",
      "3     1.0       0.0             Allison, Mr. Hudson Joshua Creighton    male   \n",
      "4     1.0       0.0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
      "\n",
      "       age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
      "0  29.0000    0.0    0.0   24160  211.3375       B5        S    2    NaN   \n",
      "1   0.9167    1.0    2.0  113781  151.5500  C22 C26        S   11    NaN   \n",
      "2   2.0000    1.0    2.0  113781  151.5500  C22 C26        S  NaN    NaN   \n",
      "3  30.0000    1.0    2.0  113781  151.5500  C22 C26        S  NaN  135.0   \n",
      "4  25.0000    1.0    2.0  113781  151.5500  C22 C26        S  NaN    NaN   \n",
      "\n",
      "                         home.dest  \n",
      "0                     St Louis, MO  \n",
      "1  Montreal, PQ / Chesterville, ON  \n",
      "2  Montreal, PQ / Chesterville, ON  \n",
      "3  Montreal, PQ / Chesterville, ON  \n",
      "4  Montreal, PQ / Chesterville, ON  \n",
      "\n",
      "Aug_test Dataset:\n",
      "   enrollee_id      city  city_development_index  gender  \\\n",
      "0        32403   city_41                   0.827    Male   \n",
      "1         9858  city_103                   0.920  Female   \n",
      "2        31806   city_21                   0.624    Male   \n",
      "3        27385   city_13                   0.827    Male   \n",
      "4        27724  city_103                   0.920    Male   \n",
      "\n",
      "       relevent_experience enrolled_university education_level  \\\n",
      "0  Has relevent experience    Full time course        Graduate   \n",
      "1  Has relevent experience       no_enrollment        Graduate   \n",
      "2   No relevent experience       no_enrollment     High School   \n",
      "3  Has relevent experience       no_enrollment         Masters   \n",
      "4  Has relevent experience       no_enrollment        Graduate   \n",
      "\n",
      "  major_discipline experience company_size company_type last_new_job  \\\n",
      "0             STEM          9          <10          NaN            1   \n",
      "1             STEM          5          NaN      Pvt Ltd            1   \n",
      "2              NaN         <1          NaN      Pvt Ltd        never   \n",
      "3             STEM         11        10/49      Pvt Ltd            1   \n",
      "4             STEM        >20       10000+      Pvt Ltd           >4   \n",
      "\n",
      "   training_hours  \n",
      "0              21  \n",
      "1              98  \n",
      "2              15  \n",
      "3              39  \n",
      "4              72  \n",
      "\n",
      "Housing Prices Dataset:\n",
      "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
      "0  13300000  7420         4          2        3      yes        no       no   \n",
      "1  12250000  8960         4          4        4      yes        no       no   \n",
      "2  12250000  9960         3          2        2      yes        no      yes   \n",
      "3  12215000  7500         4          2        2      yes        no      yes   \n",
      "4  11410000  7420         4          1        2      yes       yes      yes   \n",
      "\n",
      "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
      "0              no             yes        2      yes        furnished  \n",
      "1              no             yes        3       no        furnished  \n",
      "2              no              no        2      yes   semi-furnished  \n",
      "3              no             yes        3      yes        furnished  \n",
      "4              no             yes        2       no        furnished  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "titanic_data = pd.read_csv('titanic3.csv')\n",
    "aug_test_data = pd.read_csv('aug_test.csv')\n",
    "housing_data = pd.read_csv('housing_prices.csv')\n",
    "\n",
    "print(\"Titanic Dataset:\")\n",
    "print(titanic_data.head())\n",
    "print(\"\\nAug_test Dataset:\")\n",
    "print(aug_test_data.head())\n",
    "print(\"\\nHousing Prices Dataset:\")\n",
    "print(housing_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe53a8b8-21a0-4de7-90e8-8e047dad9b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic Missing Values:\n",
      "pclass          1\n",
      "survived        1\n",
      "name            1\n",
      "sex             1\n",
      "age           264\n",
      "sibsp           1\n",
      "parch           1\n",
      "ticket          1\n",
      "fare            2\n",
      "cabin        1015\n",
      "embarked        3\n",
      "boat          824\n",
      "body         1189\n",
      "home.dest     565\n",
      "dtype: int64\n",
      "\n",
      "Aug_test Missing Values:\n",
      "enrollee_id                 0\n",
      "city                        0\n",
      "city_development_index      0\n",
      "gender                    508\n",
      "relevent_experience         0\n",
      "enrolled_university        31\n",
      "education_level            52\n",
      "major_discipline          312\n",
      "experience                  5\n",
      "company_size              622\n",
      "company_type              634\n",
      "last_new_job               40\n",
      "training_hours              0\n",
      "dtype: int64\n",
      "\n",
      "Housing Prices Missing Values:\n",
      "price               0\n",
      "area                0\n",
      "bedrooms            0\n",
      "bathrooms           0\n",
      "stories             0\n",
      "mainroad            0\n",
      "guestroom           0\n",
      "basement            0\n",
      "hotwaterheating     0\n",
      "airconditioning     0\n",
      "parking             0\n",
      "prefarea            0\n",
      "furnishingstatus    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Titanic Missing Values:\")\n",
    "print(titanic_data.isnull().sum())\n",
    "print(\"\\nAug_test Missing Values:\")\n",
    "print(aug_test_data.isnull().sum())\n",
    "print(\"\\nHousing Prices Missing Values:\")\n",
    "print(housing_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6a69a63-317d-4573-bacf-1c49c2cc17ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic dataset missing values after preprocessing:\n",
      "pclass      1\n",
      "survived    1\n",
      "name        1\n",
      "sex         1\n",
      "age         0\n",
      "sibsp       1\n",
      "parch       1\n",
      "ticket      1\n",
      "fare        0\n",
      "embarked    0\n",
      "dtype: int64\n",
      "\n",
      "Aug_test dataset missing values after preprocessing:\n",
      "enrollee_id               0\n",
      "city                      0\n",
      "city_development_index    0\n",
      "gender                    0\n",
      "relevent_experience       0\n",
      "enrolled_university       0\n",
      "education_level           0\n",
      "major_discipline          0\n",
      "experience                0\n",
      "company_size              0\n",
      "company_type              0\n",
      "last_new_job              0\n",
      "training_hours            0\n",
      "dtype: int64\n",
      "\n",
      "Housing Prices dataset missing values after preprocessing:\n",
      "price               0\n",
      "area                0\n",
      "bedrooms            0\n",
      "bathrooms           0\n",
      "stories             0\n",
      "mainroad            0\n",
      "guestroom           0\n",
      "basement            0\n",
      "hotwaterheating     0\n",
      "airconditioning     0\n",
      "parking             0\n",
      "prefarea            0\n",
      "furnishingstatus    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "titanic_data = pd.read_csv('titanic3.csv')\n",
    "aug_test_data = pd.read_csv('aug_test.csv')\n",
    "housing_data = pd.read_csv('housing_prices.csv')\n",
    "titanic_data['age'] = titanic_data['age'].fillna(titanic_data['age'].median())\n",
    "titanic_data['fare'] = titanic_data['fare'].fillna(titanic_data['fare'].median())\n",
    "titanic_data['embarked'] = titanic_data['embarked'].fillna(titanic_data['embarked'].mode()[0])\n",
    "titanic_data = titanic_data.drop(['cabin', 'boat', 'body', 'home.dest'], axis=1)\n",
    "aug_test_data['gender'] = aug_test_data['gender'].fillna(aug_test_data['gender'].mode()[0])\n",
    "aug_test_data['enrolled_university'] = aug_test_data['enrolled_university'].fillna(aug_test_data['enrolled_university'].mode()[0])\n",
    "aug_test_data['education_level'] = aug_test_data['education_level'].fillna(aug_test_data['education_level'].mode()[0])\n",
    "aug_test_data['major_discipline'] = aug_test_data['major_discipline'].fillna(aug_test_data['major_discipline'].mode()[0])\n",
    "aug_test_data['experience'] = aug_test_data['experience'].fillna(aug_test_data['experience'].mode()[0])\n",
    "aug_test_data['company_size'] = aug_test_data['company_size'].fillna(aug_test_data['company_size'].mode()[0])\n",
    "aug_test_data['company_type'] = aug_test_data['company_type'].fillna(aug_test_data['company_type'].mode()[0])\n",
    "aug_test_data['last_new_job'] = aug_test_data['last_new_job'].fillna(aug_test_data['last_new_job'].mode()[0])\n",
    "print(\"Titanic dataset missing values after preprocessing:\")\n",
    "print(titanic_data.isnull().sum())\n",
    "\n",
    "print(\"\\nAug_test dataset missing values after preprocessing:\")\n",
    "print(aug_test_data.isnull().sum())\n",
    "\n",
    "print(\"\\nHousing Prices dataset missing values after preprocessing:\")\n",
    "print(housing_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4983754a-31cd-4127-b737-b846c3c1951c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic dataset missing values after preprocessing:\n",
      "pclass      0\n",
      "survived    0\n",
      "name        0\n",
      "sex         0\n",
      "age         0\n",
      "sibsp       0\n",
      "parch       0\n",
      "ticket      0\n",
      "fare        0\n",
      "embarked    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e5f5314-d3ae-478f-a165-efb36bf9958d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Titanic Data (first 5 rows):\n",
      "        age      fare\n",
      "0 -0.038931  3.444003\n",
      "1 -2.216698  2.287674\n",
      "2 -2.132692  2.287674\n",
      "3  0.038615  2.287674\n",
      "4 -0.349118  2.287674\n",
      "\n",
      "Scaled Housing Data (first 5 rows):\n",
      "   bedrooms  bathrooms   parking\n",
      "0  1.403419   1.421812  1.517692\n",
      "1  1.403419   5.405809  2.679409\n",
      "2  0.047278   1.421812  1.517692\n",
      "3  1.403419   1.421812  2.679409\n",
      "4  1.403419  -0.570187  1.517692\n",
      "\n",
      "Titanic dataset split:\n",
      "X_train_titanic: (1048, 10), X_test_titanic: (262, 10)\n",
      "y_train_titanic: (1048,), y_test_titanic: (262,)\n",
      "\n",
      "Housing dataset split:\n",
      "X_train_housing: (436, 13), X_test_housing: (109, 13)\n",
      "y_train_housing: (436,), y_test_housing: (109,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For numerical columns, use Standard Scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Titanic: Apply scaling to 'Age' and 'Fare'\n",
    "titanic_data[['age', 'fare']] = scaler.fit_transform(titanic_data[['age', 'fare']])\n",
    "\n",
    "# Housing Prices: Apply scaling to numerical columns\n",
    "numerical_columns = ['bedrooms', 'bathrooms', 'parking']  # Example numerical columns\n",
    "housing_data[numerical_columns] = scaler.fit_transform(housing_data[numerical_columns])\n",
    "\n",
    "# Check scaled Titanic dataset\n",
    "print(\"Scaled Titanic Data (first 5 rows):\")\n",
    "print(titanic_data[['age', 'fare']].head())\n",
    "\n",
    "# Check scaled Housing Prices dataset\n",
    "print(\"\\nScaled Housing Data (first 5 rows):\")\n",
    "print(housing_data[numerical_columns].head())\n",
    "\n",
    "# Titanic: Split dataset into train and test sets\n",
    "X_titanic = titanic_data.drop('survived', axis=1)\n",
    "y_titanic = titanic_data['survived']\n",
    "X_train_titanic, X_test_titanic, y_train_titanic, y_test_titanic = train_test_split(X_titanic, y_titanic, test_size=0.2, random_state=42)\n",
    "\n",
    "# Housing Prices: Split dataset into train and test sets\n",
    "X_housing = housing_data.drop('price', axis=1)\n",
    "y_housing = housing_data['price']\n",
    "X_train_housing, X_test_housing, y_train_housing, y_test_housing = train_test_split(X_housing, y_housing, test_size=0.2, random_state=42)\n",
    "\n",
    "# Output the shape of train/test sets to verify\n",
    "print(\"\\nTitanic dataset split:\")\n",
    "print(f\"X_train_titanic: {X_train_titanic.shape}, X_test_titanic: {X_test_titanic.shape}\")\n",
    "print(f\"y_train_titanic: {y_train_titanic.shape}, y_test_titanic: {y_test_titanic.shape}\")\n",
    "\n",
    "print(\"\\nHousing dataset split:\")\n",
    "print(f\"X_train_housing: {X_train_housing.shape}, X_test_housing: {X_test_housing.shape}\")\n",
    "print(f\"y_train_housing: {y_train_housing.shape}, y_test_housing: {y_test_housing.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05540700-a129-4ca7-a7dd-009425a316e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Mayne, Mlle. Berthe Antonine (\"Mrs de Villiers\")'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Train a Random Forest Classifier for Titanic dataset\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model_titanic \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel_titanic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_titanic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_titanic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set\u001b[39;00m\n\u001b[0;32m      9\u001b[0m y_pred_titanic \u001b[38;5;241m=\u001b[39m model_titanic\u001b[38;5;241m.\u001b[39mpredict(X_test_titanic)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:360\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 360\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[0;32m    373\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)(criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2961\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2959\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m   2960\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2961\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1370\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m     )\n\u001b[0;32m   1368\u001b[0m ensure_all_finite \u001b[38;5;241m=\u001b[39m _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[1;32m-> 1370\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1375\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1387\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1389\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:973\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pandas_requires_conversion:\n\u001b[0;32m    969\u001b[0m     \u001b[38;5;66;03m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001b[39;00m\n\u001b[0;32m    970\u001b[0m     \u001b[38;5;66;03m# nans\u001b[39;00m\n\u001b[0;32m    971\u001b[0m     \u001b[38;5;66;03m# Use the original dtype for conversion if dtype is None\u001b[39;00m\n\u001b[0;32m    972\u001b[0m     new_dtype \u001b[38;5;241m=\u001b[39m dtype_orig \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dtype\n\u001b[1;32m--> 973\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# Since we converted here, we do not need to convert again later\u001b[39;00m\n\u001b[0;32m    975\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   6639\u001b[0m     ]\n\u001b[0;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Mayne, Mlle. Berthe Antonine (\"Mrs de Villiers\")'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train a Random Forest Classifier for Titanic dataset\n",
    "model_titanic = RandomForestClassifier(random_state=42)\n",
    "model_titanic.fit(X_train_titanic, y_train_titanic)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_titanic = model_titanic.predict(X_test_titanic)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_titanic = accuracy_score(y_test_titanic, y_pred_titanic)\n",
    "print(\"Titanic Model Accuracy:\", accuracy_titanic)\n",
    "print(classification_report(y_test_titanic, y_pred_titanic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08690719-1254-4f2d-88bf-cab36389a468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
